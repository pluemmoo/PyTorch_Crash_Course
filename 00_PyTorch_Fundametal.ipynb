{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1800403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db96de8",
   "metadata": {},
   "source": [
    "## Understanding the Tensor\n",
    "\n",
    "Tensor is difference from scalar, vector, and matrix because it can represent more dimensions from 0, to n. while matrix or vector can represent 2 or matrix.\n",
    "\n",
    "You can refer more description of tensor and other fundamental operation in PyTorch from: https://www.learnpytorch.io/00_pytorch_fundamentals/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf2b53",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "\n",
    "A scalar is the single number, so it have zero dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b1ec58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(9)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e585527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc052ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781eaac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the python integer value from the scalar tensor, this operation work only for scalar tensor\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e964de7",
   "metadata": {},
   "source": [
    "Vector is single dimension tensor that can contain many multiple numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69396824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([1, 2, 3])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8be66c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75841ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this shape ilustrates the amount of element inside the vector or current dimension.\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3875f4b",
   "metadata": {},
   "source": [
    "Matrix is two dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a95b7040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5509138b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a098c612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed796f5",
   "metadata": {},
   "source": [
    "The shape of the matrix is [3, 3] because matrix is three elements deep and three wide.\n",
    "What if we shrink the element to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9202f037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2], [4, 5], [7, 8]])\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4466d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5eba900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [1, 2], \n",
    "            [4, 5], \n",
    "            [7, 8],\n",
    "            [7, 8],\n",
    "        ],\n",
    "        [\n",
    "            [1, 2], \n",
    "            [4, 5], \n",
    "            [7, 8],\n",
    "            [7, 8],\n",
    "        ],\n",
    "        [\n",
    "            [1, 2], \n",
    "            [4, 5], \n",
    "            [7, 8],\n",
    "            [7, 8],\n",
    "        ],\n",
    "        \n",
    "    ]\n",
    "    )\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfcbe575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e2cdb",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
    "Torch Random Tensors:https://docs.pytorch.org/docs/stable/generated/torch.rand.html#torch-rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e99ad0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4152, 0.1565, 0.7456, 0.5493],\n",
       "        [0.4066, 0.5307, 0.2377, 0.0590],\n",
       "        [0.0125, 0.1524, 0.0519, 0.8404]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29b04304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([3, 4]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim,random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "425b0af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4702, 0.6995, 0.8378,  ..., 0.4657, 0.4709, 0.3552],\n",
       "         [0.7214, 0.2022, 0.8042,  ..., 0.2727, 0.7618, 0.6621],\n",
       "         [0.7409, 0.8397, 0.6620,  ..., 0.8972, 0.7137, 0.5146],\n",
       "         ...,\n",
       "         [0.1571, 0.1176, 0.9581,  ..., 0.2756, 0.2053, 0.6191],\n",
       "         [0.9383, 0.9981, 0.5570,  ..., 0.7450, 0.9995, 0.8800],\n",
       "         [0.3169, 0.6501, 0.2547,  ..., 0.4988, 0.6797, 0.2915]],\n",
       "\n",
       "        [[0.6926, 0.2761, 0.1472,  ..., 0.1120, 0.5826, 0.2622],\n",
       "         [0.3587, 0.2071, 0.0397,  ..., 0.7490, 0.5807, 0.2322],\n",
       "         [0.5252, 0.9178, 0.9664,  ..., 0.6350, 0.1628, 0.1435],\n",
       "         ...,\n",
       "         [0.2659, 0.3539, 0.5036,  ..., 0.6384, 0.1689, 0.3617],\n",
       "         [0.3611, 0.7942, 0.9333,  ..., 0.1765, 0.2341, 0.9283],\n",
       "         [0.7921, 0.9334, 0.5869,  ..., 0.9729, 0.4521, 0.7652]],\n",
       "\n",
       "        [[0.0753, 0.5587, 0.7045,  ..., 0.8291, 0.4679, 0.3728],\n",
       "         [0.2723, 0.7811, 0.5830,  ..., 0.4501, 0.8686, 0.3911],\n",
       "         [0.3052, 0.8536, 0.5785,  ..., 0.7414, 0.7908, 0.5656],\n",
       "         ...,\n",
       "         [0.6947, 0.5706, 0.4032,  ..., 0.2030, 0.6358, 0.3692],\n",
       "         [0.1607, 0.2420, 0.6829,  ..., 0.8891, 0.4890, 0.6108],\n",
       "         [0.3732, 0.9365, 0.2383,  ..., 0.9777, 0.8106, 0.2768]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3, 254, 254)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9f52abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([3, 254, 254]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim,random_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf372d",
   "metadata": {},
   "source": [
    "## Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b46f1dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with all zeros\n",
    "zeros_tensor = torch.zeros(3, 4)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e51e6c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with all ones\n",
    "ones_tensor = torch.ones(3, 4)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e027e101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34810111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor * random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c8b78",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7366066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/fn2_r29930s6nq_wqwxq_ckm0000gn/T/ipykernel_48780/558156120.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.range() if this function deprecated, use torch.arange()\n",
    "torch.range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "195ff8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(start=0, end=10, step=2)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66c42b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros # we got the same shape and dtype as one_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeba53f",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e874e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor \n",
    "float_32_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0], \n",
    "    dtype=torch.float16, # Default is float32\n",
    "    device=None, # None means CPU. What device that tensor will be stored on\n",
    "    requires_grad=False # Track gradients for this tensor (default is False)\n",
    "    )\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51a20100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685922c",
   "metadata": {},
   "source": [
    "The output is still float32 because the default value of pytorch is float32\n",
    "<br>\n",
    "The different between float32 and float 16 or other is the number which float32 will store in memory than float16 or lower which meaning that float32 will compute lower than float16. If develop model that need very high accuracy float32 might be the great choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "547bcb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensors = float_32_tensor.type(torch.float16)\n",
    "float_16_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "adafc399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float16)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_16_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5e722c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ce50c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float16)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_16_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084cc0a",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "1. Tensors not right datatype. (get datatypes - tensor.dtype)\n",
    "2. Tensors not right shape. (get shape - tensor.shape)\n",
    "3. Tensors not on the right device. (get device - tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "701b662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create some tensors\n",
    "some_tensor = torch.tensor([2,3])\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a3f73217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype of some_tensor: torch.int64\n",
      "shape of some_tensor: torch.Size([2])\n",
      "device of some_tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"datatype of some_tensor:\", some_tensor.dtype)\n",
    "print(\"shape of some_tensor:\", some_tensor.shape)\n",
    "print(\"device of some_tensor:\", some_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af04a5b",
   "metadata": {},
   "source": [
    "### Manipulating tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication (element wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4972208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a23df558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply the tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6a4c331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract 10 from the tensor\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a4312de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide the tensor by 10\n",
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42d4773a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out PyTorch in-built functions\n",
    "torch.mul(tensor, 10)  # multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909dd3e3",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "There are two main rules that performing matrix multiplcation needs to satisfy:\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3, 2) @ (3, 2)` won't work\n",
    "* `(2, 3) @ (3, 2)`  will work\n",
    "* `(3, 2) @ (2, 3)`  will work\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "* `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "* `(3, 2) @ (2, 3)` -> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "036dd27b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# illustrate error of shape mismatch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# illustrate error of shape mismatch\n",
    "torch.matmul(torch.rand(3, 2), torch.rand(3, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "230b88ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)  # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64ef33cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f27673",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a7662ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m tensor_A = torch.tensor([[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m], \n\u001b[32m      2\u001b[39m                          [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m],\n\u001b[32m      3\u001b[39m                          [\u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m]])\n\u001b[32m      5\u001b[39m tensor_B = torch.tensor([[\u001b[32m7\u001b[39m, \u001b[32m8\u001b[39m],\n\u001b[32m      6\u001b[39m                          [\u001b[32m9\u001b[39m, \u001b[32m10\u001b[39m],\n\u001b[32m      7\u001b[39m                          [\u001b[32m11\u001b[39m, \u001b[32m12\u001b[39m]])\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# matrix multiplication\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1, 2], \n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 8],\n",
    "                         [9, 10],\n",
    "                         [11, 12]])\n",
    "\n",
    "torch.mm(tensor_A, tensor_B)  # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b2f9e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  9, 11],\n",
       "        [ 8, 10, 12]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose a tensor\n",
    "tensor_B.T  # transpose of tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "158fea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23,  29,  35],\n",
       "        [ 53,  67,  81],\n",
       "        [ 83, 105, 127]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)  # matrix multiplication with transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ac647",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a1798ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "81efe7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f487c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d0d2feca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4b9acfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean - note: torch.mean() requires float tensors\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8cead60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5959691",
   "metadata": {},
   "source": [
    "### Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6dec0f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7979cf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmin() -> return the index of the minimum value\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2fbde9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bc8fc26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the maximum value with argmax() -> return the index of the maximum value\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4c52f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b3cbd",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e95f05f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape # 10 elements in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "359e8d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1, 9) # 9 * 1 = 10 need to be the same as the original tensor size\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "01788502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9b0a6aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changeing z changes x (because they share the same memory as the original tensor)\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8655a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([4, 9]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "abe7ea9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze - remove all dimensions of size 1\n",
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c16402fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.squeeze(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "df5d0edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.squeeze(x, 0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "26b405d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1, 2])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.squeeze(x, 1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d9c421c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped\n",
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "04341c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed = x_reshaped.squeeze()\n",
    "x_squeezed, x_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "910f3a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "New tensor: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "new tensor shape: torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - add a dimension of size 1 to a target tensor at a specific dimension\n",
    "print(f\"Previous target: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
    "print(f\"New tensor: {x_unsqueezed}\")\n",
    "print(f\"new tensor shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2df106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.permute() - rearrange the order of a target tnesor in a specified order \n",
    "# often used in image data\n",
    "x = torch.rand(2, 3, 5)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "485d6624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.permute(x, (2, 0, 1)).shape  # change the order of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7c0f5a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x_original = torch.rand(224, 224, 3)  # height, width, color_channels\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\") # color_channels, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "99bbacf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6666, 0.6783, 0.9261,  ..., 0.9460, 0.9559, 0.4680],\n",
       "         [0.6721, 0.7860, 0.7761,  ..., 0.3166, 0.0214, 0.5446],\n",
       "         [0.3436, 0.1851, 0.4135,  ..., 0.6925, 0.2374, 0.4489],\n",
       "         ...,\n",
       "         [0.2865, 0.5333, 0.3209,  ..., 0.7363, 0.4633, 0.1089],\n",
       "         [0.7115, 0.7547, 0.9695,  ..., 0.4826, 0.6102, 0.3398],\n",
       "         [0.0225, 0.0489, 0.3057,  ..., 0.0445, 0.3262, 0.6813]],\n",
       "\n",
       "        [[0.4579, 0.2036, 0.4027,  ..., 0.5964, 0.1889, 0.5637],\n",
       "         [0.2286, 0.5608, 0.4086,  ..., 0.9377, 0.8596, 0.0107],\n",
       "         [0.9846, 0.0612, 0.7889,  ..., 0.9780, 0.0048, 0.6083],\n",
       "         ...,\n",
       "         [0.4136, 0.8130, 0.9166,  ..., 0.8352, 0.3468, 0.1092],\n",
       "         [0.7541, 0.5513, 0.4765,  ..., 0.1137, 0.0379, 0.3266],\n",
       "         [0.1157, 0.0153, 0.5014,  ..., 0.5475, 0.9747, 0.5223]],\n",
       "\n",
       "        [[0.5434, 0.5445, 0.4795,  ..., 0.6406, 0.0533, 0.8700],\n",
       "         [0.0636, 0.6459, 0.4684,  ..., 0.8405, 0.6123, 0.3717],\n",
       "         [0.2433, 0.9649, 0.3200,  ..., 0.0388, 0.6357, 0.8228],\n",
       "         ...,\n",
       "         [0.6767, 0.1675, 0.9637,  ..., 0.6696, 0.6058, 0.0320],\n",
       "         [0.6327, 0.7950, 0.7685,  ..., 0.1411, 0.3759, 0.8036],\n",
       "         [0.7280, 0.5573, 0.2517,  ..., 0.2773, 0.0633, 0.4228]]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0] = 0.6666\n",
    "x_permuted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c208f7",
   "metadata": {},
   "source": [
    "## Indexing (seecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "583ea89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13810e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on our new tensor\n",
    "x[0] # index on the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a8e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the middle bracket (dim=1)\n",
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "69e3bbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the most inner bracket (dim=2)\n",
    "x[0, 0, 0]  # index on the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8ffb3a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \":\" to select all values in a dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cc0fbccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of 0th and 1st dimensions but only the 1st value of the last dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9445c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension, but only the 1 index value of 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9d03c611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of the last dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fa398b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "x[:, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4f2ea937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 3, 6, 9\n",
    "x[:, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3f6f4",
   "metadata": {},
   "source": [
    "## PyTorch Tensor & NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library.\n",
    "Because of this, PyTorch has funtionality to interact with it.\n",
    "* Data in Numpy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c87d1f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy Array to Tensor\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "array = np.arange(1., 8.) # defaut dtype is float64\n",
    "tensor = torch.from_numpy(array).type(torch.float32)  # convert to float32 tensor\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e1d45037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a3f112bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 4., 5., 6., 7., 8., 9.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, What will this do to `tensor`?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c987108",
   "metadata": {},
   "source": [
    "So array and tensor doesn't share the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "945b8bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()  # convert to numpy array\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d07f516",
   "metadata": {},
   "source": [
    "since pytorch have dtype is float 32, so when convert to numpy it will get the pytorch default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d6c00fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, What happens to `numpy_tensor`?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89c014",
   "metadata": {},
   "source": [
    "So they don't share memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483be1f",
   "metadata": {},
   "source": [
    "## Reproducbility (trying take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better represen\n",
    "tations of data -> again -> again -> again...`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**\n",
    "\n",
    "Essentially what the random seed does is \"flavour\" the randomness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab555ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4566, 0.5275, 0.3903, 0.5066],\n",
      "        [0.5441, 0.6262, 0.3359, 0.2589],\n",
      "        [0.8291, 0.2653, 0.3055, 0.0012]])\n",
      "tensor([[0.4255, 0.8876, 0.9511, 0.7919],\n",
      "        [0.7842, 0.8883, 0.3934, 0.4504],\n",
      "        [0.1135, 0.8835, 0.9264, 0.8968]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B) \n",
    "print(random_tensor_A == random_tensor_B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2594ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "import torch\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED) # only work in one block of code\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)  # should be all False since they are random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d7bb9",
   "metadata": {},
   "source": [
    "Extra Resources for reproducibility:\n",
    "* https://docs.pytorch.org/docs/stable/notes/randomness.html\n",
    "* https://en.wikipedia.org/wiki/Random_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6395fcef",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on the GPU (and making faster computations)\n",
    "\n",
    "GPU = Faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0538e",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "\n",
    "1. Easiest - Use Goodle Colab for a free GPU (options to upgrade as well)\n",
    "2. Use your own GPU - takes a little bit setup and requires the inverstment of purchasing a GPU, there's lots of options...\n",
    "3. Use cloud computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them\n",
    "\n",
    "For 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this refer to PyTorch setup documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2e9c0",
   "metadata": {},
   "source": [
    "### 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80d16bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with PTorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e47fcb",
   "metadata": {},
   "source": [
    "For PyTorch since it's capable of running compute on the GPU or CPU, it's best practice to setup device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4744abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set up device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d7613f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b24d8a",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and models) on the GPU\n",
    "\n",
    "The  reason we want out tensors/models on the GPU is because using a GPU results in faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f313a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# create a tensor (default is on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f27a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3], device='cuda:0'), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU if available\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu, tensor_on_gpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a0ff8b",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6262919",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to Numpy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtensor_on_gpu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# this will raise an error if you have GPU access\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to Numpy\n",
    "tensor_on_gpu.numpy()  # this will raise an error if you have GPU access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4253538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), 'cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu, tensor_back_on_cpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fedbea86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dcd477",
   "metadata": {},
   "source": [
    "## Exercises & Extra-Curriculum\n",
    "\n",
    "see exercises for this notebook here: https://www.learnpytorch.io/00_pytorch_fundamentals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462bb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3b0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
